#!/usr/bin/env python3
"""
FastGPT å¯åŠ¨è„šæœ¬
æ”¯æŒç¯å¢ƒå˜é‡é…ç½®å’Œå‘½ä»¤è¡Œå‚æ•°
"""

import os
import sys
import argparse
import uvicorn
from pathlib import Path

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    # é»˜è®¤ç¯å¢ƒå˜é‡
    defaults = {
        'HOST': '0.0.0.0',
        'PORT': '7434',
        'PROCESSES_PER_GPU': '1',
        'LOG_LEVEL': 'info'
    }
    
    for key, value in defaults.items():
        if key not in os.environ:
            os.environ[key] = value
    
    # è®¾ç½®æ­£ç¡®çš„ TORCH_DEVICE
    if 'TORCH_DEVICE' not in os.environ or os.environ['TORCH_DEVICE'] == 'auto':
        try:
            import torch
            if torch.cuda.is_available():
                os.environ['TORCH_DEVICE'] = 'cuda'
            else:
                os.environ['TORCH_DEVICE'] = 'cpu'
        except ImportError:
            os.environ['TORCH_DEVICE'] = 'cpu'

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–é¡¹"""
    try:
        import torch
        import fastapi
        import marker
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… FastAPI: {fastapi.__version__}")
        print(f"âœ… Marker: {marker.__version__ if hasattr(marker, '__version__') else 'installed'}")
        
        # æ£€æŸ¥CUDA
        if torch.cuda.is_available():
            print(f"âœ… CUDA: {torch.version.cuda}")
            print(f"âœ… GPUæ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        return False

def check_config_files():
    """æ£€æŸ¥é…ç½®æ–‡ä»¶"""
    config_file = Path("openai_ocr_config.json")
    if config_file.exists():
        print(f"âœ… é…ç½®æ–‡ä»¶: {config_file}")
        try:
            import json
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            print(f"   é¢„è®¾é…ç½®æ•°é‡: {len(config)}")
            print(f"   å¯ç”¨é¢„è®¾: {list(config.keys())}")
        except Exception as e:
            print(f"âš ï¸  é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
    else:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")

def main():
    parser = argparse.ArgumentParser(description='FastGPT API æœåŠ¡å™¨')
    parser.add_argument('--host', default=os.getenv('HOST', '0.0.0.0'), 
                       help='æœåŠ¡å™¨ä¸»æœºåœ°å€ (é»˜è®¤: 0.0.0.0)')
    parser.add_argument('--port', type=int, default=int(os.getenv('PORT', '7434')), 
                       help='æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 7434)')
    parser.add_argument('--processes-per-gpu', type=int, 
                       default=int(os.getenv('PROCESSES_PER_GPU', '1')),
                       help='æ¯ä¸ªGPUçš„è¿›ç¨‹æ•° (é»˜è®¤: 1)')
    parser.add_argument('--log-level', default=os.getenv('LOG_LEVEL', 'info'),
                       choices=['debug', 'info', 'warning', 'error'],
                       help='æ—¥å¿—çº§åˆ« (é»˜è®¤: info)')
    parser.add_argument('--reload', action='store_true',
                       help='å¯ç”¨è‡ªåŠ¨é‡è½½ (å¼€å‘æ¨¡å¼)')
    parser.add_argument('--check-only', action='store_true',
                       help='åªæ£€æŸ¥ç¯å¢ƒï¼Œä¸å¯åŠ¨æœåŠ¡å™¨')
    
    args = parser.parse_args()
    
    print("ğŸš€ FastGPT API æœåŠ¡å™¨å¯åŠ¨")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['HOST'] = args.host
    os.environ['PORT'] = str(args.port)
    os.environ['PROCESSES_PER_GPU'] = str(args.processes_per_gpu)
    os.environ['LOG_LEVEL'] = args.log_level
    
    setup_environment()
    
    # æ£€æŸ¥ä¾èµ–
    print("\nğŸ” æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
    if not check_dependencies():
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…å¿…è¦çš„ä¾èµ–")
        sys.exit(1)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    print("\nğŸ” æ£€æŸ¥é…ç½®æ–‡ä»¶...")
    check_config_files()
    
    if args.check_only:
        print("\nâœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
        return
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    print(f"\nğŸŒ æœåŠ¡å™¨é…ç½®:")
    print(f"   ä¸»æœº: {args.host}")
    print(f"   ç«¯å£: {args.port}")
    print(f"   æ¯GPUè¿›ç¨‹æ•°: {args.processes_per_gpu}")
    print(f"   æ—¥å¿—çº§åˆ«: {args.log_level}")
    print(f"   è‡ªåŠ¨é‡è½½: {'æ˜¯' if args.reload else 'å¦'}")
    
    print(f"\nğŸ“š APIæ–‡æ¡£:")
    print(f"   Swagger UI: http://{args.host}:{args.port}/docs")
    print(f"   ReDoc: http://{args.host}:{args.port}/redoc")
    print(f"   å¥åº·æ£€æŸ¥: http://{args.host}:{args.port}/v2/health")
    
    print(f"\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print(f"   curl -X POST \"http://{args.host}:{args.port}/v2/parse/file\" \\")
    print(f"     -F \"file=@document.pdf\" \\")
    print(f"     -F \"output_format=markdown\"")
    
    print("\n" + "=" * 50)
    print("ğŸ¯ æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    
    try:
        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            "fastgpt:app",
            host=args.host,
            port=args.port,
            log_level=args.log_level,
            reload=args.reload,
            access_log=True
        )
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æœåŠ¡å™¨å·²åœæ­¢")
    except Exception as e:
        print(f"\nâŒ æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
