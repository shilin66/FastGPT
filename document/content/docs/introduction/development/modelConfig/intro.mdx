---
title: FastGPT 模型配置说明
description: FastGPT 模型配置说明
---

import { Alert } from '@/components/docs/Alert';

## 配置模型


### 1. 配置介绍

#### 核心配置

- 模型 ID：接口请求时候，Body 中`model`字段的值，全局唯一。
- 自定义请求地址/Key：该模型的访问地址和Key

#### 模型类型

1. 语言模型 - 进行文本对话，多模态模型支持图片识别。
2. 索引模型 - 对文本块进行索引，用于相关文本检索。
4. 语音合成 - 将文本转换为语音。
5. 语音识别 - 将语音转换为文本。

#### 启用模型

系统内置了目前主流厂商的模型，如果你不熟悉配置，直接点击`启用`即可

![alt text](/imgs/image-92.png)

#### 修改模型配置

点击模型右侧的齿轮即可进行模型配置，不同类型模型的配置有区别。

|                                 |                                 |
| ------------------------------- | ------------------------------- |
| ![alt text](/imgs/image-93.png) | ![alt text](/imgs/image-94.png) |

## 新增自定义模型

如果系统内置的模型无法满足你的需求，你可以添加自定义模型。自定义模型中，如果`模型 ID`与系统内置的模型 ID 一致，则会被认为是修改系统模型。

|                                 |                                 |
| ------------------------------- | ------------------------------- |
| ![alt text](/imgs/image-96.png) | ![alt text](/imgs/image-97.png) |

#### 通过配置文件配置

如果你觉得通过页面配置模型比较麻烦，你也可以通过配置文件来配置模型。或者希望快速将一个系统的配置，复制到另一个系统，也可以通过配置文件来实现。

|                                 |                                 |
| ------------------------------- | ------------------------------- |
| ![alt text](/imgs/image-98.png) | ![alt text](/imgs/image-99.png) |

**语言模型字段说明：**

```json
{
  "model": "模型 ID",
  "metadata": {
    "isCustom": true, // 是否为自定义模型
    "isActive": true, // 是否启用
    "provider": "OpenAI", // 模型提供商，主要用于分类展示
    "model": "gpt-5", // 模型ID
    "name": "gpt-5", // 模型别名
    "maxContext": 125000, // 最大上下文
    "maxResponse": 16000, // 最大回复
    "quoteMaxToken": 120000, // 最大引用内容
    "maxTemperature": 1.2, // 最大温度
    "charsPointsPrice": 0, // n积分/1k token（商业版）
    "censor": false, // 是否开启敏感校验（商业版）
    "vision": true, // 是否支持图片输入
    "datasetProcess": true, // 是否设置为文本理解模型（QA），务必保证至少有一个为true，否则知识库会报错
    "usedInClassify": true, // 是否用于问题分类（务必保证至少有一个为true）
    "usedInExtractFields": true, // 是否用于内容提取（务必保证至少有一个为true）
    "usedInToolCall": true, // 是否用于工具调用（务必保证至少有一个为true）
    "toolChoice": true, // 是否支持工具选择（分类，内容提取，工具调用会用到。）
    "functionCall": false, // 是否支持函数调用（分类，内容提取，工具调用会用到。会优先使用 toolChoice，如果为false，则使用 functionCall，如果仍为 false，则使用提示词模式）
    "customCQPrompt": "", // 自定义文本分类提示词（不支持工具和函数调用的模型
    "customExtractPrompt": "", // 自定义内容提取提示词
    "defaultSystemChatPrompt": "", // 对话默认携带的系统提示词
    "defaultConfig": {}, // 请求API时，挟带一些默认配置（比如 GLM4 的 top_p）
    "fieldMap": {} // 字段映射（o1 模型需要把 max_tokens 映射为 max_completion_tokens）
  }
}
```

**索引模型字段说明:**

```json
{
  "model": "模型 ID",
  "metadata": {
    "isCustom": true, // 是否为自定义模型
    "isActive": true, // 是否启用
    "provider": "OpenAI", // 模型提供商
    "model": "text-embedding-3-small", // 模型ID
    "name": "text-embedding-3-small", // 模型别名
    "charsPointsPrice": 0, // n积分/1k token
    "defaultToken": 512, // 默认文本分割时候的 token
    "maxToken": 3000 // 最大 token
  }
}
```

**重排模型字段说明:**

```json
{
  "model": "模型 ID",
  "metadata": {
    "isCustom": true, // 是否为自定义模型
    "isActive": true, // 是否启用
    "provider": "BAAI", // 模型提供商
    "model": "bge-reranker-v2-m3", // 模型ID
    "name": "ReRanker-Base", // 模型别名
    "requestUrl": "", // 自定义请求地址
    "requestAuth": "", // 自定义请求认证
    "type": "rerank" // 模型类型
  }
}
```

**语音合成模型字段说明:**

```json
{
  "model": "模型 ID",
  "metadata": {
    "isActive": true, // 是否启用
    "isCustom": true, // 是否为自定义模型
    "type": "tts", // 模型类型
    "provider": "FishAudio", // 模型提供商
    "model": "fishaudio/fish-speech-1.5", // 模型ID
    "name": "fish-speech-1.5", // 模型别名
    "voices": [
      // 音色
      {
        "label": "fish-alex", // 音色名称
        "value": "fishaudio/fish-speech-1.5:alex" // 音色ID
      },
      {
        "label": "fish-anna", // 音色名称
        "value": "fishaudio/fish-speech-1.5:anna" // 音色ID
      }
    ],
    "charsPointsPrice": 0 // n积分/1k token
  }
}
```

**语音识别模型字段说明:**

```json
{
  "model": "whisper-1",
  "metadata": {
    "isActive": true, // 是否启用
    "isCustom": true, // 是否为自定义模型
    "provider": "OpenAI", // 模型提供商
    "model": "whisper-1", // 模型ID
    "name": "whisper-1", // 模型别名
    "charsPointsPrice": 0, // n积分/1k token
    "type": "stt" // 模型类型
  }
}
```

## 模型测试

FastGPT 页面上提供了每类模型的简单测试，可以初步检查模型是否正常工作，会实际按模板发送一个请求。

![alt text](/imgs/image-105.png)

## 特殊接入示例

### ReRank 模型接入

#### 使用硅基流动的在线模型

有免费的 `bge-reranker-v2-m3` 模型可以使用。

1. [点击注册硅基流动账号](https://cloud.siliconflow.cn/i/TR9Ym0c4)
2. 进入控制台，获取 API key: https://cloud.siliconflow.cn/account/ak
3. 打开 FastGPT 模型配置，新增一个`BAAI/bge-reranker-v2-m3`的重排模型（如果系统内置了，也可以直接变更,无需新增）。

![alt text](/imgs/image-101.png)

#### 私有部署模型

[点击查看部署 ReRank 模型教程](/docs/introduction/development/custom-models/bge-rerank/)

### 接入语音识别模型


点击模型编辑：

![alt text](/imgs/image-106.png)

填写硅基流动的地址：`https://api.siliconflow.cn/v1/audio/transcriptions`，并填写硅基流动的 API Key。

![alt text](/imgs/image-107.png)

## 其他配置项说明

### 自定义请求地址

直接向自定义请求地址发起请求。需要填写完整的请求地址，例如：

- LLM: [host]/v1/chat/completions
- Embedding: [host]/v1/embeddings
- STT: [host]/v1/audio/transcriptions
- TTS: [host]/v1/audio/speech
- Rerank: [host]/v1/rerank

自定义请求 Key，则是向自定义请求地址发起请求时候，携带请求头：Authorization: Bearer xxx 进行请求。

所有接口均遵循 OpenAI 提供的模型格式，可参考 [OpenAI API 文档](https://platform.openai.com/docs/api-reference/introduction) 进行配置。

### 模型价格配置

用户可以通过配置模型价格，来进行账号计费。系统包含两种计费模式：按总 tokens 计费和输入输出 Tokens 分开计费。

如果需要配置`输入输出 Tokens 分开计费模式`，则填写`模型输入价格`和`模型输出价格`两个值。
如果需要配置`按总 tokens 计费模式`，则填写`模型综合价格`一个值。